{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_roi_to_fixed_size(roi, target_size=(640, 640)):\n",
    "    h, w = roi.shape[:2]\n",
    "    target_w, target_h = target_size\n",
    "\n",
    "    # Calculate scaling factor\n",
    "    scale = min(target_w / w, target_h / h)\n",
    "    new_w = int(w * scale)\n",
    "    new_h = int(h * scale)\n",
    "\n",
    "    # Resize ROI\n",
    "    resized_roi = cv2.resize(roi, (new_w, new_h), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    # Create a blank canvas with the target size\n",
    "    canvas = np.zeros((target_h, target_w, 3), dtype=np.uint8)\n",
    "\n",
    "    # Center the resized ROI on the canvas\n",
    "    top = (target_h - new_h) // 2\n",
    "    left = (target_w - new_w) // 2\n",
    "    canvas[top:top+new_h, left:left+new_w] = resized_roi\n",
    "\n",
    "    return canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 (no detections), 823.9ms\n",
      "Speed: 10.3ms preprocess, 823.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 793.6ms\n",
      "Speed: 3.1ms preprocess, 793.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Yield, 902.1ms\n",
      "Speed: 5.3ms preprocess, 902.1ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 835.8ms\n",
      "Speed: 3.5ms preprocess, 835.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Speed_Limit_20, 767.9ms\n",
      "Speed: 9.5ms preprocess, 767.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Speed_Limit_30, 862.6ms\n",
      "Speed: 3.6ms preprocess, 862.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 798.2ms\n",
      "Speed: 10.8ms preprocess, 798.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Speed_Limit_20, 736.1ms\n",
      "Speed: 15.3ms preprocess, 736.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 745.0ms\n",
      "Speed: 6.0ms preprocess, 745.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 759.6ms\n",
      "Speed: 24.2ms preprocess, 759.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Speed_Limit_30, 726.1ms\n",
      "Speed: 14.3ms preprocess, 726.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Speed_Limit_20, 686.2ms\n",
      "Speed: 3.4ms preprocess, 686.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 805.3ms\n",
      "Speed: 3.9ms preprocess, 805.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Speed_Limit_20, 952.5ms\n",
      "Speed: 3.1ms preprocess, 952.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 662.3ms\n",
      "Speed: 3.0ms preprocess, 662.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Speed_Limit_20, 669.1ms\n",
      "Speed: 6.1ms preprocess, 669.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 637.5ms\n",
      "Speed: 3.4ms preprocess, 637.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Speed_Limit_20, 646.7ms\n",
      "Speed: 3.7ms preprocess, 646.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 703.9ms\n",
      "Speed: 3.5ms preprocess, 703.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Speed_Limit_20, 667.0ms\n",
      "Speed: 5.6ms preprocess, 667.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 700.2ms\n",
      "Speed: 3.6ms preprocess, 700.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 664.0ms\n",
      "Speed: 3.4ms preprocess, 664.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Speed_Limit_20, 657.0ms\n",
      "Speed: 7.3ms preprocess, 657.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Priority_Road, 639.1ms\n",
      "Speed: 3.5ms preprocess, 639.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 641.0ms\n",
      "Speed: 4.0ms preprocess, 641.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Priority_Road, 655.2ms\n",
      "Speed: 4.5ms preprocess, 655.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 757.9ms\n",
      "Speed: 3.4ms preprocess, 757.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 700.7ms\n",
      "Speed: 3.5ms preprocess, 700.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 580.6ms\n",
      "Speed: 3.4ms preprocess, 580.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 718.8ms\n",
      "Speed: 20.5ms preprocess, 718.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load YOLO model\n",
    "model = YOLO(\"./best.pt\")\n",
    "\n",
    "# Helper function: Resize ROI to fixed size\n",
    "def resize_roi_to_fixed_size(roi, target_size=(640, 640)):\n",
    "    h, w = roi.shape[:2]\n",
    "    target_w, target_h = target_size\n",
    "\n",
    "    # Calculate scaling factor\n",
    "    scale = min(target_w / w, target_h / h)\n",
    "    new_w = int(w * scale)\n",
    "    new_h = int(h * scale)\n",
    "\n",
    "    # Resize ROI\n",
    "    resized_roi = cv2.resize(roi, (new_w, new_h), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    # Create a blank canvas with the target size\n",
    "    canvas = np.zeros((target_h, target_w, 3), dtype=np.uint8)\n",
    "\n",
    "    # Center the resized ROI on the canvas\n",
    "    top = (target_h - new_h) // 2\n",
    "    left = (target_w - new_w) // 2\n",
    "    canvas[top:top+new_h, left:left+new_w] = resized_roi\n",
    "\n",
    "    return canvas\n",
    "\n",
    "# Helper function: Map bounding box from resized ROI to original frame\n",
    "def map_bbox_to_original_frame(bbox, roi_coords, original_size, target_size=(640, 640)):\n",
    "    x_roi, y_roi, w_roi, h_roi = roi_coords\n",
    "    orig_w, orig_h = original_size\n",
    "    target_w, target_h = target_size\n",
    "\n",
    "    scale_x = orig_w / target_w\n",
    "    scale_y = orig_h / target_h\n",
    "\n",
    "    x1, y1, x2, y2 = bbox\n",
    "    x1 = int(x1 * scale_x + x_roi)\n",
    "    y1 = int(y1 * scale_y + y_roi)\n",
    "    x2 = int(x2 * scale_x + x_roi)\n",
    "    y2 = int(y2 * scale_y + y_roi)\n",
    "\n",
    "    return x1, y1, x2, y2\n",
    "\n",
    "# Shape detection and real-time video processing\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Resize the frame for faster processing\n",
    "    scale_percent = 50\n",
    "    width = int(frame.shape[1] * scale_percent / 100)\n",
    "    height = int(frame.shape[0] * scale_percent / 100)\n",
    "    frame_resized = cv2.resize(frame, (width, height))\n",
    "\n",
    "    # Convert to grayscale and apply Gaussian blur\n",
    "    gray = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "    edges = cv2.Canny(blurred, 50, 150)\n",
    "\n",
    "    # Find contours\n",
    "    contours, hierarchy = cv2.findContours(edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    for i, contour in enumerate(contours):\n",
    "        if hierarchy[0][i][3] != -1:  # Ignore nested contours\n",
    "            continue\n",
    "\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area < 500:  # Ignore small contours\n",
    "            continue\n",
    "\n",
    "        # Approximate the shape\n",
    "        epsilon = 0.04 * cv2.arcLength(contour, True)\n",
    "        approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "\n",
    "        # Detect shapes and ROI\n",
    "        x, y, w, h = cv2.boundingRect(approx)\n",
    "        shape = None\n",
    "        if len(approx) == 3:\n",
    "            shape = \"Triangle\"\n",
    "        elif len(approx) == 4:\n",
    "            shape = \"Rectangle\"\n",
    "        elif len(approx) > 4:\n",
    "            (cx, cy), radius = cv2.minEnclosingCircle(contour)\n",
    "            if radius > 10:\n",
    "                shape = \"Circle\"\n",
    "\n",
    "        if shape:\n",
    "            roi = frame_resized[y:y+h, x:x+w]  # Extract the ROI\n",
    "            resized_roi = resize_roi_to_fixed_size(roi, target_size=(640, 640))  # Resize ROI\n",
    "\n",
    "            # YOLO inference\n",
    "            results = model.predict(resized_roi, conf=0.5, imgsz=640)  # YOLO inference\n",
    "\n",
    "            for result in results[0].boxes:\n",
    "                conf = result.conf.item()\n",
    "                cls = result.cls.item()\n",
    "                label = results[0].names[int(cls)]\n",
    "\n",
    "                if conf > 0.5:  # Adjust confidence threshold\n",
    "                    # Map bbox back to original frame\n",
    "                    x1, y1, x2, y2 = map_bbox_to_original_frame(\n",
    "                        result.xyxy[0].tolist(), (x, y, w, h), (width, height)\n",
    "                    )\n",
    "\n",
    "                    # Draw detections on the original frame\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                    cv2.putText(frame, f\"{label} ({conf:.2f})\", \n",
    "                                (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow(\"Shape and Sign Detection\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
